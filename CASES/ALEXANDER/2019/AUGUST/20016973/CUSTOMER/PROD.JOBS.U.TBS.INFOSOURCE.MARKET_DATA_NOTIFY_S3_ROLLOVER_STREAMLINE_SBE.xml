<?xml version="1.0" encoding="UTF-8"?>
<jobs>
   <metadata>
      <row>
         <version>12.3.1</version>
      </row>
   </metadata>
   <general_attributes>
      <row>
         <minimum_ae_version>11.2</minimum_ae_version>
         <archive_key2>00541374</archive_key2>
         <auto_deactivation>F</auto_deactivation>
         <child_flags>00000000000000000000000000000000</child_flags>
         <deactivation_condition>ANY_OK</deactivation_condition>
         <ert>4</ert>
         <platform>UNIX</platform>
         <last_runtimes>AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA</last_runtimes>
         <max_parallel_action>1</max_parallel_action>
         <mrt>25200</mrt>
         <mrt_alarm>SYSTEM.SCRIPT.X.UC4.X.OBJ_RUNNING_TOO_LONG</mrt_alarm>
         <mrt_method>513</mrt_method>
         <mrt_time>000000</mrt_time>
         <name>PROD.JOBS.U.TBS.INFOSOURCE.MARKET_DATA_NOTIFY_S3_ROLLOVER_STREAMLINE_SBE</name>
         <type>JOBS</type>
         <inherit_output_filter>N</inherit_output_filter>
         <queue>CLIENT_QUEUE</queue>
         <description>Checks whether MD Flink Capture is completed for the given trade date</description>
         <versioning_id>-1646104353</versioning_id>
      </row>
   </general_attributes>
   <scripts>
      <row>
         <process><![CDATA[echo "Checking s3://&S3_BUCKET#/&S3_PREFIX#/&TRADE_DATE#"

CMD='/usr/local/bin/cash start -f notify-s3rollover -args "--bucket &S3_BUCKET# --dataFileLocation &S3_PREFIX#/&TRADE_DATE#/ --notifyTimeoutMax 3600 --lastUpdateTimeout 1200 --checkS3Interval 120"'

echo "Running command on &EMR_COORDINATOR_HOST#: "
echo ${CMD}

printf "\n***************************************************\n"

eval "$CMD"
]]></process>
      </row>
      <row>
         <pre_process><![CDATA[:INCLUDE PROD.INCLUDE.X.TBS.INFOSOURCE.DATAMINE_CLOUD_AWS_SETTINGS

! set the coordinator as this job's host
:INCLUDE PROD.INCLUDE.X.TBS.INFOSOURCE.SET_DATAMINE_COORDINATOR_AS_HOST

:SET &EXEC_DATE# = SYS_LDATE('YYYYMMDD')
:SET &JOB_ID# = SYS_ACT_ME_NR()

:INCLUDE PROD.INCLUDE.X.TBS.INFOSOURCE.MARKET_DATA_PIPELINE_PATHS_CLOUD

! parameters for jenkins job to provision the ec2 instance
:SET &S3_BUCKET# = &EDH_BUCKET#
:SET &S3_PREFIX# = &RAW_SSBE_MD_CAPTURE_PREFIX#
:SET &TRADE_DATE# = &EXEC_DATE#
]]></pre_process>
      </row>
   </scripts>
   <job_attributes>
      <row>
         <activation_at_runtime>1</activation_at_runtime>
         <platform>UNIX</platform>
         <agent><![CDATA[<UNIX>]]></agent>
         <job_report_path>2</job_report_path>
         <priority>0</priority>
         <unix_shell></unix_shell>
         <unix_shell_options></unix_shell_options>
         <unix_type></unix_type>
         <unix_cmd></unix_cmd>
      </row>
   </job_attributes>
   <rollback_definitions>
      <row>
      </row>
   </rollback_definitions>
</jobs>
